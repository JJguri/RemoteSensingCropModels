{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjojeda\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import dateutil\n",
    "import pylab as py\n",
    "import seaborn as sns\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import sklearn.metrics\n",
    "from numpy  import array\n",
    "import glob\n",
    "import functools\n",
    "from functools import reduce\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,mark_inset)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get APSIM data and process the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c06091eda93e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Open apsim outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Sorghum_V6.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mapsim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Select * from DailyReport\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Read the Simulations table that has SimulationID matched to SimulationName\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mread_sql_query\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mRead\u001b[0m \u001b[0mSQL\u001b[0m \u001b[0mquery\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \"\"\"\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;31m# is_cursor should not be necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_engine_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0m_is_sqlalchemy_connectable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSQLDatabase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_is_sqlalchemy_connectable\u001b[1;34m(con)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_SQLALCHEMY_INSTALLED\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0m_SQLALCHEMY_INSTALLED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_util\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minspect\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBLANK_SCHEMA\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckConstraint\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumn\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\schema.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSchemaVisitor\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mddl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_CreateDropBase\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mddl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_DDLCompiles\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Open apsim outputs\n",
    "con = sqlite3.connect(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Sorghum_V6.db')\n",
    "apsim = pd.read_sql(\"Select * from DailyReport\", con)\n",
    "\n",
    "#Read the Simulations table that has SimulationID matched to SimulationName\n",
    "Simulations = pd.read_sql(\"Select * from _Simulations\",con)\n",
    "Simulations.set_index('ID',inplace=True)\n",
    "apsim.loc[:,'SimulationName'] = [Simulations.loc[apsim.loc[x,'SimulationID'],'Name'] for x in apsim.index]\n",
    "\n",
    "#reduce the dataframes\n",
    "df=apsim.drop(['CheckpointID', 'SimulationID', 'Zone',\n",
    "       'Sorghum.AboveGroundDead.Wt', 'Sorghum.AboveGroundLive.Wt', 'Leaf.Wt',\n",
    "       'Stem.Wt', 'PanicleWt', 'Sorghum.Phenology.FinalLeafNo',\n",
    "       'Sorghum.Leaf.LeafNo', 'Leaf.CoverDead',\n",
    "       'Leaf.CoverTotal', 'Leaf.SenescedLai', 'Leaf.LAITotal',\n",
    "       'Leaf.LAIDead', 'Leaf.LAI', 'Leaf.Height', 'Arbitrator.DeltaWt',\n",
    "       'Sorghum.Phenology.FloweringDAS', 'Sorghum.Phenology.MaturityDAS',\n",
    "       'Das', 'Leaf.ExpansionStress.WaterStressEffect',\n",
    "       'Leaf.ExpansionStress.NitrogenStressEffect', 'Leaf.Photosynthesis.FW',\n",
    "       'Leaf.Photosynthesis.FN', 'Leaf.WaterDemand', 'Leaf.WaterAllocation',\n",
    "       'actualET', 'potentialET', 'deficitET', 'Sorghum.Leaf.Transpiration',\n",
    "       'Soil.SoilWater.Eo', 'Soil.SoilWater.Es', 'Arbitrator.SWAvailRatio',\n",
    "       'Arbitrator.SDRatio', 'Arbitrator.WatSupply', 'SowingDate', 'Cultivar',\n",
    "       'SowingDepth', 'RowSpacing', 'SowDensity', 'Weather.FileName',\n",
    "       'Weather.Latitude', 'Weather.Longitude', 'Weather.Amp', 'Weather.Tav',\n",
    "       'rainfall', 'Weather.MinT', 'Weather.MaxT', 'radiation', 'Weather.VPD',\n",
    "       'Weather.Qmax', 'Leaf.Allocated.Wt', 'Stem.Allocated.Wt',\n",
    "       'Grain.Allocated.Wt', 'Rachis.Allocated.Wt', 'Root.Allocated.Wt', 'Trate'],axis=1) \n",
    "\n",
    "df.rename(columns={'Clock.Today':'Date','Leaf.CoverGreen':'Cover'}, inplace=True)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['JDay'] = df['Date'].dt.dayofyear.apply(lambda x: str(x).zfill(3))\n",
    "df['year'] = df['year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"JDay\"] = pd.to_numeric(data[\"JDay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create MODIS ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['modis1'] = ((data.JDay >= 1) & (data.JDay <= 16)).map({True:'1', False:None})\n",
    "data['modis2'] = ((data.JDay >= 17) & (data.JDay <= 33)).map({True:'2', False:None})\n",
    "data['modis3'] = ((data.JDay >= 34) & (data.JDay <= 49)).map({True:'3', False:None})\n",
    "data['modis4'] = ((data.JDay >= 50) & (data.JDay <= 65)).map({True:'4', False:None})\n",
    "data['modis5'] = ((data.JDay >= 66) & (data.JDay <= 81)).map({True:'5', False:None})\n",
    "data['modis6'] = ((data.JDay >= 82) & (data.JDay <= 97)).map({True:'6', False:None})\n",
    "data['modis7'] = ((data.JDay >= 98) & (data.JDay <= 113)).map({True:'7', False:None})\n",
    "data['modis8'] = ((data.JDay >= 114) & (data.JDay <= 129)).map({True:'8', False:None})\n",
    "data['modis9'] = ((data.JDay >= 130) & (data.JDay <= 145)).map({True:'9', False:None})\n",
    "data['modis10'] = ((data.JDay >= 146) & (data.JDay <= 161)).map({True:'10', False:None})\n",
    "data['modis11'] = ((data.JDay >= 162) & (data.JDay <= 177)).map({True:'11', False:None})\n",
    "data['modis12'] = ((data.JDay >= 178) & (data.JDay <= 193)).map({True:'12', False:None})\n",
    "data['modis13'] = ((data.JDay >= 194) & (data.JDay <= 209)).map({True:'13', False:None})\n",
    "data['modis14'] = ((data.JDay >= 210) & (data.JDay <= 225)).map({True:'14', False:None})\n",
    "data['modis15'] = ((data.JDay >= 226) & (data.JDay <= 241)).map({True:'15', False:None})\n",
    "data['modis16'] = ((data.JDay >= 242) & (data.JDay <= 257)).map({True:'16', False:None})\n",
    "data['modis17'] = ((data.JDay >= 258) & (data.JDay <= 273)).map({True:'17', False:None})\n",
    "data['modis18'] = ((data.JDay >= 274) & (data.JDay <= 289)).map({True:'18', False:None})\n",
    "data['modis19'] = ((data.JDay >= 290) & (data.JDay <= 305)).map({True:'19', False:None})\n",
    "data['modis20'] = ((data.JDay >= 306) & (data.JDay <= 321)).map({True:'20', False:None})\n",
    "data['modis21'] = ((data.JDay >= 322) & (data.JDay <= 337)).map({True:'21', False:None})\n",
    "data['modis22'] = ((data.JDay >= 338) & (data.JDay <= 353)).map({True:'22', False:None})\n",
    "data['modis23'] = ((data.JDay >= 354) & (data.JDay <= 366)).map({True:'23', False:None})\n",
    "\n",
    "data['modis']=data['modis1'].fillna('') + data['modis2'].fillna('') + data['modis3'].fillna('') + data['modis4'].fillna('') + data['modis5'].fillna('') + data['modis6'].fillna('') + data['modis7'].fillna('') + data['modis8'].fillna('') + data['modis9'].fillna('') + data['modis10'].fillna('') + data['modis11'].fillna('') + data['modis12'].fillna('') + data['modis13'].fillna('') + data['modis14'].fillna('') + data['modis15'].fillna('') + data['modis16'].fillna('') + data['modis17'].fillna('') + data['modis18'].fillna('') + data['modis19'].fillna('') + data['modis20'].fillna('') + data['modis21'].fillna('') + data['modis22'].fillna('') + data['modis23'].fillna('')\n",
    "\n",
    "#reduce the dataframes\n",
    "df=data.drop(['modis1','modis2','modis3','modis4','modis5','modis6','modis7','modis8',\n",
    "             'modis9','modis10','modis11','modis12','modis13','modis14','modis15','modis16','modis17','modis18',\n",
    "             'modis19','modis20','modis21','modis22','modis23'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\df.csv', index=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calculate statistics for APSIM simulations based on MODIS dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.groupby(['modis','SimulationName','year'], as_index=False)['Cover', 'RadInt', 'AGGR'].mean().round(decimals=2)\n",
    "df_min = df.groupby(['modis','SimulationName','year'], as_index=False)['Cover', 'RadInt', 'AGGR'].min().round(decimals=2)\n",
    "df_max = df.groupby(['modis','SimulationName','year'], as_index=False)['Cover', 'RadInt', 'AGGR'].max().round(decimals=2)\n",
    "#agg_median = df.groupby(['modis','Year','SimulationName'], as_index=False)['Cover', 'RadInt', 'AGGR'].median().round(decimals=2)\n",
    "#agg_std = df.groupby(['modis','Year','SimulationName'], as_index=False)['Cover', 'RadInt', 'AGGR'].std().round(decimals=2)\n",
    "#agg_q25 = df.groupby(['modis','Year','SimulationName'], as_index=False)['Cover', 'RadInt', 'AGGR'].quantile(.25).round(decimals=2)\n",
    "#agg_q75 = df.groupby(['modis','Year','SimulationName'], as_index=False)['Cover', 'RadInt', 'AGGR'].quantile(.75).round(decimals=2)\n",
    "\n",
    "df_mean.rename(columns={'Cover':'Cover_APSIM','RadInt':'RadInt_APSIM','AGGR':'AGGR_APSIM'}, inplace=True)\n",
    "df_min.rename(columns={'Cover':'Cover_APSIM','RadInt':'RadInt_APSIM','AGGR':'AGGR_APSIM'}, inplace=True)\n",
    "df_max.rename(columns={'Cover':'Cover_APSIM_max','RadInt':'RadInt_APSIM_max','AGGR':'AGGR_APSIM_max'}, inplace=True)\n",
    "\n",
    "st0 = pd.merge(df_mean, df_min, on=['modis','SimulationName','year'])\n",
    "st0.rename(columns={'Cover_APSIM_x':'Cover_APSIM_mean','RadInt_APSIM_x':'RadInt_APSIM_mean',\n",
    "                   'AGGR_APSIM_x':'AGGR_APSIM_mean','Cover_APSIM_y':'Cover_APSIM_min','RadInt_APSIM_y':'RadInt_APSIM_min',\n",
    "                   'AGGR_APSIM_y':'AGGR_APSIM_min'}, inplace=True)\n",
    "\n",
    "st00 = [st0, df_max]\n",
    "st = reduce(lambda  left,right: pd.merge(left,right,on=['modis','SimulationName','year'], how='outer'), st00)\n",
    "st.rename(columns={'SimulationName':'SN'}, inplace=True)\n",
    "st[\"modis\"] = st[\"modis\"].astype(str).astype(int)\n",
    "#st.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\df_mean.csv', index=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merge observed MODIS data and APSIM data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs=pd.read_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\others\\df_MODIS_OriginalClean.csv')\n",
    "modis = pd.merge(st, obs, on = ['SN','modis','year'])\n",
    "#modis.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\df_MODIS.csv', index=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create another dataframe to make the line plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis0=modis\n",
    "modis0\n",
    "\n",
    "modisObs=modis0.drop(['Cover_APSIM_mean', 'RadInt_APSIM_mean',\n",
    "       'AGGR_APSIM_mean', 'Cover_APSIM_min', 'RadInt_APSIM_min',\n",
    "       'AGGR_APSIM_min', 'Cover_APSIM_max', 'RadInt_APSIM_max',\n",
    "       'AGGR_APSIM_max','Cover_MODIS_SD', 'RadInt_MODIS_SD', 'AGGR_MODIS_SD'],axis=1) \n",
    "modisObs['source']='MODIS'\n",
    "\n",
    "modisObs.rename(columns={'Cover_MODIS_mean':'Cover_mean','RadInt_MODIS_mean':'RadInt_mean', 'AGGR_MODIS_mean':'AGGR_mean',\n",
    "       'Cover_MODIS_min':'Cover_min','RadInt_MODIS_min':'RadInt_min','AGGR_MODIS_min':'AGGR_min',\n",
    "       'Cover_MODIS_max':'Cover_max','RadInt_MODIS_max':'RadInt_max','AGGR_MODIS_max':'AGGR_max'}, inplace=True)\n",
    "\n",
    "modisPre=modis0.drop(['Cover_MODIS_mean', 'RadInt_MODIS_mean',\n",
    "       'AGGR_MODIS_mean', 'Cover_MODIS_min', 'RadInt_MODIS_min',\n",
    "       'AGGR_MODIS_min', 'Cover_MODIS_max', 'RadInt_MODIS_max',\n",
    "       'AGGR_MODIS_max', 'Cover_MODIS_SD', 'RadInt_MODIS_SD', 'AGGR_MODIS_SD'],axis=1) \n",
    "modisPre['source']='APSIM'\n",
    "\n",
    "modisPre.rename(columns={'Cover_APSIM_mean':'Cover_mean','RadInt_APSIM_mean':'RadInt_mean', 'AGGR_APSIM_mean':'AGGR_mean',\n",
    "       'Cover_APSIM_min':'Cover_min','RadInt_APSIM_min':'RadInt_min','AGGR_APSIM_min':'AGGR_min',\n",
    "       'Cover_APSIM_max':'Cover_max','RadInt_APSIM_max':'RadInt_max','AGGR_APSIM_max':'AGGR_max'}, inplace=True)\n",
    "\n",
    "df_final = pd.concat([modisPre,modisObs])\n",
    "df_final = df_final[['source','SN','year','modis','modisID','Cover_mean','Cover_max','Cover_min',\n",
    "                     'AGGR_mean','AGGR_max','AGGR_min','RadInt_mean','RadInt_max','RadInt_min']]\n",
    "\n",
    "#Need to sort manually add the column date before to go to the other jupyter notebook!!!!!!\n",
    "#df_final.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\df_MODIS_v2.csv', index=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aggregate S2 to MODIS temporal resolution -failed attempt- :(**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data for the line plots\n",
    "dfS2=pd.read_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\df_S2.csv')\n",
    "dfS2[\"Cover_S2_mean\"] = pd.to_numeric(dfS2.Cover_S2_mean, errors='coerce')\n",
    "dfS2[\"CoverError\"] = pd.to_numeric(dfS2.CoverError, errors='coerce')\n",
    "dfS2[\"RadInt_S2_mean\"] = pd.to_numeric(dfS2.RadInt_S2_mean, errors='coerce')\n",
    "dfS2[\"RadIntError\"] = pd.to_numeric(dfS2.RadIntError, errors='coerce')\n",
    "dfS2[\"AGGR_S2_mean\"] = pd.to_numeric(dfS2.AGGR_S2_mean, errors='coerce')\n",
    "dfS2[\"AGGRError\"] = pd.to_numeric(dfS2.AGGRError, errors='coerce')\n",
    "\n",
    "dfS2['date'] = pd.to_datetime(dfS2['date'], errors='coerce')\n",
    "dfS2['JDay'] = dfS2['date'].dt.dayofyear.apply(lambda x: str(x).zfill(3))\n",
    "dfS2['year'] = dfS2['year'] = dfS2['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS2=dfS2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS2[\"JDay\"] = pd.to_numeric(data[\"JDay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS2['modis1'] = ((dataS2.JDay >= 1) & (dataS2.JDay <= 16)).map({True:'1', False:None})\n",
    "dataS2['modis2'] = ((dataS2.JDay >= 17) & (dataS2.JDay <= 33)).map({True:'2', False:None})\n",
    "dataS2['modis3'] = ((dataS2.JDay >= 34) & (dataS2.JDay <= 49)).map({True:'3', False:None})\n",
    "dataS2['modis4'] = ((dataS2.JDay >= 50) & (dataS2.JDay <= 65)).map({True:'4', False:None})\n",
    "dataS2['modis5'] = ((dataS2.JDay >= 66) & (dataS2.JDay <= 81)).map({True:'5', False:None})\n",
    "dataS2['modis6'] = ((dataS2.JDay >= 82) & (dataS2.JDay <= 97)).map({True:'6', False:None})\n",
    "dataS2['modis7'] = ((dataS2.JDay >= 98) & (dataS2.JDay <= 113)).map({True:'7', False:None})\n",
    "dataS2['modis8'] = ((dataS2.JDay >= 114) & (dataS2.JDay <= 129)).map({True:'8', False:None})\n",
    "dataS2['modis9'] = ((dataS2.JDay >= 130) & (dataS2.JDay <= 145)).map({True:'9', False:None})\n",
    "dataS2['modis10'] = ((dataS2.JDay >= 146) & (dataS2.JDay <= 161)).map({True:'10', False:None})\n",
    "dataS2['modis11'] = ((dataS2.JDay >= 162) & (dataS2.JDay <= 177)).map({True:'11', False:None})\n",
    "dataS2['modis12'] = ((dataS2.JDay >= 178) & (dataS2.JDay <= 193)).map({True:'12', False:None})\n",
    "dataS2['modis13'] = ((dataS2.JDay >= 194) & (dataS2.JDay <= 209)).map({True:'13', False:None})\n",
    "dataS2['modis14'] = ((dataS2.JDay >= 210) & (dataS2.JDay <= 225)).map({True:'14', False:None})\n",
    "dataS2['modis15'] = ((dataS2.JDay >= 226) & (dataS2.JDay <= 241)).map({True:'15', False:None})\n",
    "dataS2['modis16'] = ((dataS2.JDay >= 242) & (dataS2.JDay <= 257)).map({True:'16', False:None})\n",
    "dataS2['modis17'] = ((dataS2.JDay >= 258) & (dataS2.JDay <= 273)).map({True:'17', False:None})\n",
    "dataS2['modis18'] = ((dataS2.JDay >= 274) & (dataS2.JDay <= 289)).map({True:'18', False:None})\n",
    "dataS2['modis19'] = ((dataS2.JDay >= 290) & (dataS2.JDay <= 305)).map({True:'19', False:None})\n",
    "dataS2['modis20'] = ((dataS2.JDay >= 306) & (dataS2.JDay <= 321)).map({True:'20', False:None})\n",
    "dataS2['modis21'] = ((dataS2.JDay >= 322) & (dataS2.JDay <= 337)).map({True:'21', False:None})\n",
    "dataS2['modis22'] = ((dataS2.JDay >= 338) & (dataS2.JDay <= 353)).map({True:'22', False:None})\n",
    "dataS2['modis23'] = ((dataS2.JDay >= 354) & (dataS2.JDay <= 366)).map({True:'23', False:None})\n",
    "\n",
    "dataS2['modis']=dataS2['modis1'].fillna('') + dataS2['modis2'].fillna('') + dataS2['modis3'].fillna('') + dataS2['modis4'].fillna('') + dataS2['modis5'].fillna('') + dataS2['modis6'].fillna('') + dataS2['modis7'].fillna('') + dataS2['modis8'].fillna('') + dataS2['modis9'].fillna('') + dataS2['modis10'].fillna('') + dataS2['modis11'].fillna('') + dataS2['modis12'].fillna('') + dataS2['modis13'].fillna('') + dataS2['modis14'].fillna('') + dataS2['modis15'].fillna('') + dataS2['modis16'].fillna('') + dataS2['modis17'].fillna('') + dataS2['modis18'].fillna('') + dataS2['modis19'].fillna('') + dataS2['modis20'].fillna('') + dataS2['modis21'].fillna('') + dataS2['modis22'].fillna('') + dataS2['modis23'].fillna('')\n",
    "\n",
    "#reduce the dataS2frames\n",
    "dfS2agg=dataS2.drop(['modis1','modis2','modis3','modis4','modis5','modis6','modis7','modis8',\n",
    "             'modis9','modis10','modis11','modis12','modis13','modis14','modis15','modis16','modis17','modis18',\n",
    "             'modis19','modis20','modis21','modis22','modis23'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS2agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS2agg_mean = dfS2agg.groupby(['modis','SN','Field'], as_index=False)['Cover_APSIM',\n",
    "       'RadInt_APSIM', 'AGGR_APSIM', 'Cover_S2_mean', 'CoverError',\n",
    "       'RadInt_S2_mean', 'RadIntError', 'AGGR_S2_mean', 'AGGRError',\n",
    "       'Cover_S2_max', 'Cover_S2_min', 'RadInt_S2_max', 'RadInt_S2_min',\n",
    "       'AGGR_S2_max', 'AGGR_S2_min'].mean().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS2agg_mean.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\test.csv', index=None, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "kw = {'color' : [\"r\",\"green\"]}\n",
    "g = sns.FacetGrid(test, col=\"Field\", col_wrap=5, height=3, ylim=(0, 1), hue_kws=kw)\n",
    "\n",
    "g.map(plt.plot, \"date\", \"Cover_S2_mean\", linestyle=\"-\",linewidth=3).add_legend(prop=dict(size=12),\n",
    "                                                                             bbox_to_anchor=(0.98, 0.74), \n",
    "                                                                             borderaxespad=0., ncol=1,framealpha=0.3)\n",
    "g.map(plt.plot, \"date\", \"Cover_S2_min\", linestyle=\"--\",linewidth=1)\n",
    "g.map(plt.plot, \"date\", \"Cover_S2_max\", linestyle=\"--\",linewidth=1)\n",
    "g.map(plt.fill_between, \"date\", \"Cover_S2_min\",\"Cover_S2_max\", interpolate=True,alpha=0.3)\n",
    "\n",
    "#.add_legend()\n",
    "\n",
    "# Iterate thorugh each axis\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_title(ax.get_title())\n",
    "    # This only works for the left ylabels\n",
    "    ax.set_ylabel('', fontsize='medium')\n",
    "    ax.set_xlabel('', fontsize='medium')\n",
    "\n",
    "g.fig.subplots_adjust(wspace=0.03, hspace=.15)\n",
    "g.fig.text(0.01, 0.43,'Cover MODIS-APSIM (0-1)', fontsize=16, rotation=90)\n",
    "g.fig.text(0.395, 0.01,'MODIS Image Order (0-10)', fontsize=16)\n",
    "g.fig.text(0.73, 1,'Cover APSIM vs MODIS', fontsize=25, fontweight=\"bold\")\n",
    "#plt.savefig(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\modis.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get Greenseeker data and put Field data in Alldata file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0=pd.read_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\obs.csv')\n",
    "\n",
    "#reduce the dataframes\n",
    "Obs=obs0.drop(['AGB_Pre', 'Cover_Pre', 'RadInt_Pre','RUE_Pre',\n",
    "       'potentialET', 'SowingDate', 'RowSpacing', 'SowDensity', 'rain', 'tmin',\n",
    "       'tmax', 'radn', 'PAWC', 'AGGR_Pre','climate', 'soil', 'cultivar',\n",
    "       'harvest', 'prevcrop', 'tmean'],axis=1) \n",
    "\n",
    "obs=Obs.dropna(subset=['AGB_Obs', 'Cover_Obs', 'RadInt_Obs'])\n",
    "#obs.to_csv(r'C:\\Users\\jjojeda\\Google Drive\\COALAR\\Sorgo\\Python\\Field.csv', index=None, mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
